{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: hw7\n",
      "OK, version v1.13.11\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw7.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f02089e1eccc4756",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Homework 7: Scalable Data Processing Using Ray\n",
    "Contributors: Peter Schafhalter, Robert Nishihara, Edward Fang, Simon Mo, Devin Petersohn <img src=\"https://i.imgur.com/6DHvEJil.jpg\" alt=\"ray_logo\" align=\"right\" width=\"400\"/>\n",
    "\n",
    "\n",
    "## Due Date: Friday 5/3/19, 11:59PM (Last Day of Classes)\n",
    "\n",
    "## Course Policies\n",
    "\n",
    "Here are some important course policies. These are also located at\n",
    "http://www.ds100.org/sp19/.\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *write names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Assignment\n",
    "Although you've learned powerful techniques for processing data, most of the problems you've worked on involved small datasets that a single machine can quickly process. Data science in practical settings often involves processing hundreds of gigabytes, terabytes, and even petabytes of data. \n",
    "\n",
    "These data sets are too large for a single computer to process quickly, so data scientists often *scale up* their programs to *clusters*, many computers working together to run a program. On a smaller scale, we can also parallelize programs across processor cores in a single computer.\n",
    "\n",
    "For this homework, we will use [Ray](https://ray.readthedocs.io/en/latest/), a system for parallel and distributed Python (developed at Berkeley), which can parallelize programs across the cores of a single computer as well as a cluster. While your code for this homework will only parallelize across the cores of a single JupyterHub computer, you could run it on a cluster as well without any changes.\n",
    "\n",
    "Throughout this assignment, you may find it helpful to refer to the following:\n",
    "- [Ray documentation](https://ray.readthedocs.io/en/latest/)\n",
    "- [Ray codebase](https://github.com/ray-project/ray)\n",
    "\n",
    "### Note\n",
    "- This assignment will have no hidden tests and no written parts. If you pass all the tests, you are good to go!\n",
    "- This assignment will consist of a lot of reading rather than coding. If you are confused on anything, feel free to ask on Piazza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96c3cc1eaad03e69",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 1: Learning the Ray API\n",
    "\n",
    "Let's start by digging into the Ray API and familiarize ourselves with some of its functionalities. Again, please reference the [Ray documentation](https://ray.readthedocs.io/en/latest/) and [Ray codebase](https://github.com/ray-project/ray) if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e1ef66fc29a67901",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "from utils import timeit\n",
    "\n",
    "import ray\n",
    "from colorama import Fore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start Ray, we will first import ray and call `ray.init`. We will use 8 cpus. \n",
    "\n",
    "You should see something like the following, ray is telling us information about our tiny compute cluster:\n",
    "\n",
    "<img src=\"https://i.imgur.com/JOOtGFr.png\" alt=\"ray_init\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f8dd14785cef69b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:40:04,194\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-06_10-40-04_133/logs.\n",
      "2019-05-06 10:40:04,312\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:63825 to respond...\n",
      "2019-05-06 10:40:04,443\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:39223 to respond...\n",
      "2019-05-06 10:40:04,448\tINFO services.py:760 -- Starting Redis shard with 0.43 GB max memory.\n",
      "2019-05-06 10:40:04,491\tWARNING services.py:1272 -- WARNING: object_store_memory is not verified when plasma_directory is set.\n",
      "2019-05-06 10:40:04,495\tINFO services.py:1384 -- Starting the Plasma object store with 2.0 GB memory using /tmp.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'redis_address': '10.244.5.28:63825',\n",
       " 'object_store_address': '/tmp/ray/session_2019-05-06_10-40-04_133/sockets/plasma_store',\n",
       " 'webui_url': None,\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-05-06_10-40-04_133/sockets/raylet'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(\n",
    "    num_cpus=8, # We will be using 8 workers\n",
    "    include_webui=False,  \n",
    "    plasma_directory='/tmp', # The object store is mounted to local file system\n",
    "    ignore_reinit_error=True,\n",
    "    object_store_memory=int(2*1e9), \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7045bc2ef431553a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "For now, let's start with the basics. With Ray, Python objects can live either within process or within Ray's shared memory. Ray's shared memory is responsible for transfering objects among the current process and the workers, such that data is shared across different functions that might run in parallel.\n",
    "\n",
    "`ray.put(x)` copies an object `x` from the current process to Ray's shared object store and returns an ID for that object.\n",
    "\n",
    "`ray.get(x_id)` returns the object determined by the object's ID `x_id` from Ray's shared object store.\n",
    "\n",
    "You can think of this as sending python object to a in-memory database so it can be accessed by other peer python processes. \n",
    "\n",
    "If that seems a little confusing, that's ok! The following example should clear it up. The most important thing is to understand `ObjectID`s and `ray.get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-82ff4103df5d3985",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    x's type is \u001b[34m <class 'int'> \u001b[39m\n",
      "    and its value is \u001b[34m 42 \u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# x is a python object within this process.\n",
    "x = 42  \n",
    "print(f\"\"\"\n",
    "    x's type is {Fore.BLUE} {type(x)} {Fore.RESET}\n",
    "    and its value is {Fore.BLUE} {x} {Fore.RESET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we copy x to Ray's object store. This lets you share x among different Ray worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef9ad94a88be868b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    x_id's type is \u001b[34m <class 'ray._raylet.ObjectID'> \u001b[39m\n",
      "    and its value is \u001b[34m ObjectID(ffffffff4c4f3a548d6e92d41a5a22eac02e2682) \u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy x to Ray's object store. \n",
    "# This lets you share x among different Ray worker processes.\n",
    "x_id = ray.put(x)  \n",
    "print(f\"\"\"\n",
    "    x_id's type is {Fore.BLUE} {type(x_id)} {Fore.RESET}\n",
    "    and its value is {Fore.BLUE} {x_id} {Fore.RESET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the object using x_id from Ray's object store to current process with `ray.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-451658536f69adb4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    x_copy's type is \u001b[34m <class 'int'> \u001b[39m\n",
      "    and its value is \u001b[34m 42 \u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_copy = ray.get(x_id)  \n",
    "print(f\"\"\"\n",
    "    x_copy's type is {Fore.BLUE} {type(x_copy)} {Fore.RESET}\n",
    "    and its value is {Fore.BLUE} {x_copy} {Fore.RESET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83aac10013fb7d57",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You can pass a list of `ObjectID`s to `ray.get` in order to retrieve a list of objects stored in Ray's object store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2d1ec8c9fa27c46",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    x_copy's type is \u001b[34m <class 'int'> \u001b[39m\n",
      "    and its value is \u001b[34m 42 \u001b[39m\n",
      "    \n",
      "    y_copy's type is \u001b[34m <class 'int'> \u001b[39m\n",
      "    and its value is \u001b[34m 49 \u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store 49 in Ray's object store.\n",
    "y_id = ray.put(49)  \n",
    "# Retrieve a list of ObjectIDs from Ray's object store.\n",
    "x_copy, y_copy = ray.get([x_id, y_id])  \n",
    "\n",
    "print(f\"\"\"\n",
    "    x_copy's type is {Fore.BLUE} {type(x_copy)} {Fore.RESET}\n",
    "    and its value is {Fore.BLUE} {x_copy} {Fore.RESET}\n",
    "    \n",
    "    y_copy's type is {Fore.BLUE} {type(y_copy)} {Fore.RESET}\n",
    "    and its value is {Fore.BLUE} {y_copy} {Fore.RESET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a\n",
    "Store `a`, `b`, and `c` in Ray's object store and retrieve their values.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "a = \"Go bears!\"\n",
    "b = [i for i in range(10)]\n",
    "c = {\"Berkeley\": \"#1\", \"Stanford\": \"#2\"}\n",
    "\n",
    "a_id = ray.put(a)\n",
    "b_id = ray.put(b)\n",
    "c_id = ray.put(c)\n",
    "\n",
    "a_copy = ray.get(a_id)\n",
    "b_copy = ray.get(b_id)\n",
    "c_copy = ray.get(c_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 3\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q1a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a07fd7c817630544",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's try to parallelize a function using Ray. Simply add the `@ray.remote` decorator to the function you wish to parallelize.\n",
    "\n",
    "Note that using the decorator as below is [syntactic sugar](https://en.wikipedia.org/wiki/Syntactic_sugar) for `square_ray = ray.remote(square_ray)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8296ac91e75af87",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "@ray.remote\n",
    "def square_ray(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca0ec4f91f6f4305",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We'll call functions that we wish to parallelize *remote functions* because we intend to run them remotely in a different process instead of in the current process (the remote process could be on the same machine or on a different machine). A [*process*](https://en.wikipedia.org/wiki/Process_(computing)) consists of program code and activity. Programs, including those written with Ray, may consist of multiple processes which allow them to execute code in parallel.\n",
    "\n",
    "Remote functions are invoked with the `.remote()` method. You can pass function arguments to the `.remote` method which will immediately return an `ObjectID` for the return value of the function and launch a *task* that executes the function. This means that Ray returns an `ObjectID` repersenting the result of a function before the function finishes exceuting which can be useful if you'd like a long-running function to execute in the background while running other computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de3098b37ac11615",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> result_id = square_ray.remote(42)\n",
      "        result_id's type is \u001b[34m <class 'ray._raylet.ObjectID'> \u001b[39m\n",
      "        and its value is \u001b[34m ObjectID(01000000c2a399b41518d70ecf90d775c20aa240) \u001b[39m\n",
      ">>> result = ray.get(result_id)    \n",
      "        result's type is \u001b[34m <class 'int'> \u001b[39m\n",
      "        and its value is \u001b[34m 1764 \u001b[39m\n",
      ">>> 42**2\n",
      "       \u001b[34m 1764  \u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_id = square_ray.remote(42)\n",
    "\n",
    "result = ray.get(result_id)\n",
    "\n",
    "print(f\"\"\"\n",
    ">>> result_id = square_ray.remote(42)\n",
    "        result_id's type is {Fore.BLUE} {type(result_id)} {Fore.RESET}\n",
    "        and its value is {Fore.BLUE} {result_id} {Fore.RESET}\n",
    ">>> result = ray.get(result_id)    \n",
    "        result's type is {Fore.BLUE} {type(result)} {Fore.RESET}\n",
    "        and its value is {Fore.BLUE} {result} {Fore.RESET}\n",
    ">>> 42**2\n",
    "       {Fore.BLUE} {square(42)}  {Fore.RESET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "- Create a new function `slow_function_ray` using the @ray.remote decorator to turn `slow_function` into a remote function. \n",
    "- Then call the remote function and get its result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a proxy for a more interesting and computationally intensive function.\n",
    "def slow_function():\n",
    "    time.sleep(0.2)\n",
    "    return 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, implement `slow_function_ray` in the cell below.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: use a decorator here\n",
    "@ray.remote\n",
    "def slow_function_ray():\n",
    "    return slow_function()\n",
    "result = ray.get(slow_function_ray.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1c\n",
    "Now let's verify that remote functions are actually running in parallel. `slow_function` takes around 0.2 seconds to run. If we execute 2 slow functions sequentially, executing both should take $ 2 \\times 0.2 = 0.4 $ seconds. However, if we run 2 slow functions in parallel, executing both should still take only 0.2 seconds.\n",
    "\n",
    "Let's try it out! Modify the code below so that calling slow_function twice takes only 0.2 seconds to run.\n",
    "\n",
    "**HINT:** use `slow_function_ray` and the fact that calling a remote function immediately returns an `ObjectID` even if the remote function isn't done executing yet. You might need to split the code into 2 lines that:\n",
    "1. Calls the remote functions and returns `ObjectID`s\n",
    "2. Gets the results of the remote functions from the `ObjectID`s\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute results: \u001b[34m 0.20899 \u001b[39m seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# YOUR CODE HERE: \n",
    "# Make the following line execute in 0.2 seconds using Ray\n",
    "# results = [slow_function() for _ in range(2)]\n",
    "\n",
    "result_ids = [slow_function_ray.remote() for x in range(2)]\n",
    "results = [ray.get(x) for x in result_ids]\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Time to compute results: {Fore.BLUE} {end_time - start_time :.5f} {Fore.RESET} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q1c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc541ff3d6bf4d30",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Arguments to remote functions can either be regular Python objects or `ObjectID`s. Passing `ObjectID`s as arguments can be useful for calling remote functions on the results of other remote functions. This allows you to initiate tasks that depend on other tasks before any of the tasks complete.\n",
    "\n",
    "Therefore, the following is equivalent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-304048d399698d94",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 1764 == 1764 \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Call square_ray on a python object\n",
    "result1_id = square_ray.remote(42)\n",
    "\n",
    "# Call square_ray on an ObjectID\n",
    "arg_id = ray.put(42)\n",
    "result2_id = square_ray.remote(arg_id)\n",
    "\n",
    "result1, result2 = ray.get([result1_id, result2_id])\n",
    "\n",
    "print(f\"{Fore.BLUE} {result1} == {result2} {Fore.RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [*task*](https://en.wikipedia.org/wiki/Task_%28computing%29) is a loosely-defined term referring to a unit of work. In the context of Ray, tasks correspond to code which Ray executes. Calling a remote function corresponds to creating a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1d\n",
    "Let's compute $5^8$ by applying `square_ray` 3 times. The code below computes $5^8$ using `square` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5^8 = \u001b[34m 390625 \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "result = 5\n",
    "for _ in range(3):\n",
    "    result = square(result)\n",
    "\n",
    "print(f\"5^8 = {Fore.BLUE} {result} {Fore.RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Implement the code above, but now use `square_ray.remote` with only 1 call to `ray.get`.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x = 5\n",
    "for _ in range(3):\n",
    "    x = square_ray.remote(x)\n",
    "\n",
    "result = ray.get(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q1d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c92b47e2234f69e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 2: Parallel Bootstrap\n",
    "\n",
    "In previous lab, you learned how to use bootstrap to estimate mean and variance. Now, let's parallelize bootstrap using Ray in order to speed up bootstrap.\n",
    "\n",
    "Below we have the solution for how to implement `simple_resample` and `boostrap_serial`, they should look familiar to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-343b1992231109c8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def simple_resample(n):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n: an integer\n",
    "        \n",
    "    Returns:\n",
    "        an array of length n of a random sample with replacement of\n",
    "        the integers 0, 1, ..., n-1\n",
    "    \"\"\"\n",
    "    return np.random.randint(low=0, high=n, size=n)\n",
    "\n",
    "def bootstrap_serial(boot_pop, statistic, resample, replicates = 1000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        boot_pop: an array of shape n x d.\n",
    "        statistic: a function which takes boot_pop and returns a number.\n",
    "        resample: a function which takes n and returns a random sample from the integers [0, n)\n",
    "        replicates: the number of resamples\n",
    "        \n",
    "    Returns:\n",
    "        an array of length replicates, each entry being the statistic computed on a bootstrap sample of the data.\n",
    "    \"\"\"\n",
    "    n = len(boot_pop)\n",
    "    resample_estimates = np.array([statistic(boot_pop[resample(n)]) for _ in range(replicates)])\n",
    "    return resample_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f43fcc4e4cf2881",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "Use the @ray.remote decorator along with the `bootstrap_serial` function defined above to write a `bootstrap_remote` function.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0c1fc2071fa622c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: turn `bootstrap_remote` into a remote function\n",
    "@ray.remote\n",
    "def bootstrap_remote(boot_pop, statistic, resample, replicates = 1000):\n",
    "    \"\"\"Run bootstrap_serial remotely\n",
    "    Args:\n",
    "        boot_pop: an array of shape n x d.\n",
    "        statistic: a function which takes boot_pop and returns a number.\n",
    "        resample: a function which takes n and returns a random sample from the integers [0, n)\n",
    "        replicates: the number of resamples\n",
    "        \n",
    "    Returns:\n",
    "        an array of length replicates, each entry being the statistic computed on a bootstrap sample of the data.\n",
    "    \"\"\"\n",
    "    n = len(boot_pop)\n",
    "    resample_estimates = np.array([statistic(boot_pop[resample(n)]) for _ in range(replicates)])\n",
    "    return resample_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"grades_sample.csv\")\n",
    "boot_pop = np.array(data[\"Grade\"])\n",
    "num_bootstrap_resample = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7d09ce6105a8903",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap serial completed in \u001b[34m 16.32 seconds \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "boot_sample_means_serial = bootstrap_serial(boot_pop, np.mean, simple_resample, num_bootstrap_resample)\n",
    "bootstrap_serial_time = time.perf_counter() - start_time\n",
    "print(f\"Bootstrap serial completed in {Fore.BLUE} {bootstrap_serial_time:.2f} seconds {Fore.RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bcb5098798c5f34",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "That took a while to run! Now, let's implement bootstrap in parallel using your new `bootstrap_remote` function.\n",
    "- First, create 10 tasks by calling `bootstrap_remote` which each generate `num_bootstrap_resample // 10` resamples.\n",
    "- Then, get the results of the tasks.\n",
    "- Finally, merge all the results into a single array.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b741497e36ef5a4e",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap parallel completed in \u001b[34m 1.21 seconds \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "NUM_TASKS = 10\n",
    "\n",
    "boot_sample_means_parallel_ids = [bootstrap_remote.remote(boot_pop, np.mean, simple_resample, num_bootstrap_resample//NUM_TASKS)]\n",
    "boot_sample_means_parallel = [ray.get(x) for x in boot_sample_means_parallel_ids]\n",
    "boot_sample_means_parallel = np.array(boot_sample_means_parallel).flatten()\n",
    "\n",
    "bootstrap_parallel_time = time.perf_counter() - start_time\n",
    "print(f\"Bootstrap parallel completed in {Fore.BLUE} {bootstrap_parallel_time:.2f} seconds {Fore.RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79.42414452, 80.8621675 , 80.34078338, ..., 80.51154753,\n",
       "       80.69332871, 79.78797808])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_sample_means_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q2b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52447fecff96812f",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now let's examine the resulting distributions. Do they look similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b421389b46c2b59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Serial Bootstrap Distribution\")\n",
    "plt.xlabel(r\"$\\bar{X}$\")\n",
    "plt.ylabel(\"Frequency\");\n",
    "sns.distplot(boot_sample_means_serial)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Parallel Bootstrap Distribution\")\n",
    "plt.xlabel(r\"$\\bar{X}$\")\n",
    "plt.ylabel(\"Frequency\");\n",
    "sns.distplot(boot_sample_means_parallel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-214612ee2e95e181",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "At a high level, you parallelized a slow piece of code by splitting it into many tasks, and then *reduced* the result of the individual tasks to produce a output identical to the slow code.\n",
    "\n",
    "In addition, you specifically parallelized the `for` loop in `bootstrap_serial` to speed up bootstrap. Parallelizing loops can often speed up code which allows data scientists to process data more quickly.\n",
    "\n",
    "This idea of parallelizing certain code and reducing the results led to a more general programming model used to reason about and implement parallel programs called MapReduce. We'll introduce and implement MapReduce in Problem 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9793d86189e615e7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 3: Implementing MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-940d8be22eacf849",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "[MapReduce](https://en.wikipedia.org/wiki/MapReduce) a computational pattern for computing aggregate statistics of large datasets. It is the core primitive in systems like MapReduce, Hadoop, and Spark.\n",
    "\n",
    "At its core, MapReduce consists of two primitives:\n",
    "\n",
    "- The **map** transformation takes a dataset and a function and applies the function to each data point.\n",
    "- The **reduce** transformation aggregates the output of the map stage.\n",
    "\n",
    "For example, suppose that our starting point is a collection of documents. If we wish to count the number of occurrences of each word in the document, we can first apply a \"map\" transformation, which turns each document into a dictionary mapping words to the number of occurrences within that document. Then we can apply the \"reduce\" transformation, which sums the counts for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3a\n",
    "Implement `map_parallel` using the Ray API. We have provided a `map_serial` implementation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d7843be01131df0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def map_serial(function, element_lst):\n",
    "    \"\"\"Apply a function to each element of a list\n",
    "    Args:\n",
    "        function: a function that takes in one argument as input and outputs a value\n",
    "        element_lst: a list of elements that function will be applied to\n",
    "    Returns:\n",
    "        A list of all of the elements each transformed by the function\n",
    "        (ie [function(elem_1), function(elem_2), ..., function(elem_n)])\n",
    "    \"\"\"\n",
    "    return [function(elem) for elem in element_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of running `map_serial`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_serial(lambda x: x * x, [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, implement `map_parallel` in the cell below using the Ray API.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 0.0004879981279373169 s elapsed\n",
      "serial: 9.799376130104065e-06 s elapsed\n"
     ]
    }
   ],
   "source": [
    "def map_parallel(function, arglist):\n",
    "    \"\"\"Apply a function to each element of a list in parallel.\n",
    "    Args:\n",
    "        function: a remote function that takes in one argument as input and outputs an ObjectID\n",
    "        arglist: a list of arguments that the function will be applied to\n",
    "    Returns:\n",
    "        A list of ObjectIDs\n",
    "    \"\"\"\n",
    "    if not isinstance(arglist, list):\n",
    "        raise ValueError(\"The arglist argument must be a list.\")\n",
    "    \n",
    "    if not hasattr(function, \"remote\"):\n",
    "        raise ValueError(\"The function argument must be a remote function.\")\n",
    "    \n",
    "    return [function.remote(elem) for elem in arglist]     \n",
    "    \n",
    "\n",
    "\n",
    "# Please DO NOT EDIT the code below this comment\n",
    "# The code below compares map_parallel and map_serial's performance\n",
    "@ray.remote\n",
    "def square_remote(x):\n",
    "    return x * x\n",
    "\n",
    "arglist = [1, 2, 3, 4, 5]\n",
    "\n",
    "with timeit('parallel'):\n",
    "    result_ids = map_parallel(square_remote, arglist)\n",
    "\n",
    "assert isinstance(result_ids[0], ray.ObjectID), \"map_parallel should return a list of ObjectIDs\"\n",
    "\n",
    "result_ray = ray.get(result_ids)\n",
    "\n",
    "with timeit('serial'):\n",
    "    result_serial = map_serial(lambda x: x * x, arglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q3a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3326f9482c5ee91d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You may notice that for a simple function like square operating on a small list of arguments, `map_parallel` is **slower** than `map_serial`. The difference in speed is due to _communication and data transfer_ overhead between the processes which Ray uses to run functions in parallel.\n",
    "\n",
    "In general, functions that are called often and take a long time to run are good targets for parallelization. We'll explore such an example using some of Shakespeare's works in later questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3b\n",
    "Implement `reduce_parallel` using the Ray API. We have provided a `reduce_serial` implementation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e10a5ebc075fea7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def reduce_serial(function, items):\n",
    "    \"\"\"Apply a function repeatedly to pairs of items until only 1 remains\n",
    "    \n",
    "    Args:\n",
    "        function: remote function that takes 2 items as input and returns 1 new item.\n",
    "        items: a list of items which are reduced to 1 output by repeatedly calling function.\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    >>> reduce_serial(sum, [1,2,3])\n",
    "    6\n",
    "    >>> reduce_serial(lambda x, y: x - y, [3,2,1])\n",
    "    0\n",
    "    ```\n",
    "    \n",
    "    Returns the resulting item.\n",
    "    \"\"\"\n",
    "    if len(items) == 1:\n",
    "        return items[0]\n",
    "    \n",
    "    result = items[0]\n",
    "    for i in range(1, len(items)):\n",
    "        result = function(result, items[i])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now implement `reduce_parallel` below.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_parallel(function, items):\n",
    "    \"\"\"Apply a function repeatedly to pairs of items until only 1 remains.\n",
    "    \n",
    "    Args:\n",
    "        function: remote function that takes 2 items as input and returns 1 new item.\n",
    "        items: a list of items which are reduced to 1 output by repeatedly calling function.\n",
    "    \n",
    "    Returns an ObjectID.\n",
    "    \n",
    "    Hint:\n",
    "        1. Divide the list of items into pairs.\n",
    "        2. Reduce each pair to generate a new list of items.\n",
    "        3. If there was an unpaired item in (1), add it to the new list.\n",
    "        The new list should be about 1/2 the size of the old list.\n",
    "        4. If there is only 1 item in the new list, return that item. Otherwise, repeat steps 1-3.\n",
    "        \n",
    "        This algorithm is called a \"tree-reduce\", where the original items are the leaves\n",
    "        and the final result is the root. The tree is balanced. Each non-leaf node has 2 child nodes.\n",
    "        Each non-root node has 1 parent node.\n",
    "    \"\"\"\n",
    "    if not isinstance(items, list):\n",
    "        raise ValueError(\"The items argument must be a list.\")\n",
    "\n",
    "    if not hasattr(function, \"remote\"):\n",
    "        raise ValueError(\"The function argument must be a remote function.\")\n",
    "       \n",
    "    items = items.copy()   # Avoids mutating the items argument\n",
    "    while len(items) > 1:\n",
    "        new_val = function.remote(items[0], items[1])\n",
    "        items = items[2:] + [new_val]\n",
    "    return items[0]\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "# Please DO NOT EDIT the code below this comment\n",
    "# This code should help verify that reduce_parallel is working correctly\n",
    "def add_normal(a, b):\n",
    "    # Simulate a longer running function\n",
    "    # Necessary to check the correct implementation for reduce_parallel\n",
    "    time.sleep(0.3)\n",
    "    return a + b\n",
    "\n",
    "@ray.remote\n",
    "def add_remote(a, b):\n",
    "    # Simulate a longer running function\n",
    "    # Necessary to check the correct implementation for reduce_parallel\n",
    "    time.sleep(0.3)\n",
    "    return a + b\n",
    "\n",
    "items = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "start_time = time.time()\n",
    "result_serial = reduce_serial(add_normal, items)\n",
    "time_serial = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result_id = reduce_parallel(add_remote, items)\n",
    "result_parallel = ray.get(result_id)\n",
    "time_parallel = time.time() - start_time\n",
    "\n",
    "# print(f\"Time serial: {time_serial}\")\n",
    "# print(f\"Time parallel: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 3\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q3b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16ef564de43de85a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 4: Analyzing Word Frequency using MapReduce\n",
    "Let's analyze the frequency of words used in Shakespeare. For this question, we'll need to do the following:\n",
    "1. Download the text of a few of Shakespeare's plays.\n",
    "2. For each play, count the number of times each word occurs.\n",
    "3. Merge the word frequencies across plays.\n",
    "\n",
    "We've provided some helper functions that will help you with this problem below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52a8f14adcbac113",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def download_text(url):\n",
    "    \"\"\"Returns the string of text on some webpage\"\"\"\n",
    "    request = urllib.request.urlopen(url)\n",
    "    return request.read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def download_text_remote(url):\n",
    "    return download_text(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f61d41bd8d4dbcad",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"Finds the frequency of each word in a string\"\"\"\n",
    "    assert isinstance(text, str), \"text should be a string\"\n",
    "    \n",
    "    frequency = dict()\n",
    "    \n",
    "    text = text.lower()\n",
    "    matches = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    \n",
    "    for word in matches:\n",
    "        count = frequency.get(word, 0)\n",
    "        frequency[word] = count + 1\n",
    "        \n",
    "    return frequency\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def count_words_remote(text):\n",
    "    return count_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-511696b791d74ac9",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_dicts(a, b):\n",
    "    \"\"\"Merges 2 dictionaries such that the result contains keys of both a and b.\n",
    "    \n",
    "    If a key k is in a and in b, result[k] = a[k] + b[k].\n",
    "    \"\"\"\n",
    "    result = a.copy()  # Don't mutate the input dictionaries\n",
    "    for key, value in b.items():\n",
    "        result[key] = result.get(key, 0) + value\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def merge_dicts_remote(a, b):\n",
    "    return merge_dicts(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a85664ec269c1dea",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.gutenberg.org/files/1524/1524-0.txt\",       # Hamlet\n",
    "    \"https://www.gutenberg.org/cache/epub/2264/pg2264.txt\",  # Macbeth\n",
    "    \"https://www.gutenberg.org/cache/epub/2267/pg2267.txt\",  # Othello\n",
    "    \"https://www.gutenberg.org/cache/epub/1777/pg1777.txt\",  # Romeo and Juliet\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-308a358634cd8379",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "Let's now use the MapReduce API to speed up the code in the cell below. This code computes word frequencies across several of Shakespeare's works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe33c7f16a5260e5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency count serial completed in 4.286434650421143 seconds\n"
     ]
    }
   ],
   "source": [
    "# Parallelize the following code using the MapReduce API\n",
    "start_time = time.time()\n",
    "\n",
    "total_frequencies_serial = {}\n",
    "for url in urls:\n",
    "    # Download the text of the play\n",
    "    text = download_text(url)\n",
    "    # Count the frequency of each word in the play\n",
    "    frequencies = count_words(text)\n",
    "    # Add the play's word frequencies to the global word frequencies\n",
    "    total_frequencies_serial = merge_dicts(total_frequencies_serial, frequencies)\n",
    "    \n",
    "word_freq_time_serial = time.time() - start_time\n",
    "print(\"Word frequency count serial completed in {} seconds\".format(word_freq_time_serial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, speed up the code from the above cell using both `map_parallel` and `reduce_parallel`.\n",
    "\n",
    "**HINT 1:** Parallelizing loops often speeds up code.\n",
    "\n",
    "**HINT 2:** If you did question 3 correctly, you should be able to write 1 line solutions for the `...`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency count parallel completed in 0.9213650226593018 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Try to do each of these in one line!\n",
    "text_ids = map_parallel(download_text_remote, urls)\n",
    "frequency_ids = map_parallel(count_words_remote, text_ids)\n",
    "total_frequency_id = reduce_parallel(merge_dicts_remote, frequency_ids)\n",
    "total_frequencies_ray = ray.get(total_frequency_id)\n",
    "\n",
    "\n",
    "word_freq_time_parallel = time.time() - start_time\n",
    "print(\"Word frequency count parallel completed in {} seconds\".format(word_freq_time_parallel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9d9c250e73b7c65",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's examine some of Shakespeare's most used words. Surprised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dfded19a18be090",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'to', 'i', 'of', 'a', 'you', 'my', 'that', 'in']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_used_words(freq_dict, num_words=10):\n",
    "    ordered_keys = sorted(freq_dict, key=freq_dict.get, reverse=True)\n",
    "    return [word for _, word in zip(range(num_words), ordered_keys)]\n",
    "\n",
    "most_used_words(total_frequencies_ray, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc4cf6d789ac7ed2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 5: Ray Actors\n",
    "So far, we have explored Ray's *remote functions*. The tasks generated by invoking remote functions are stateless in the sense that they are intended to map inputs to outputs without side effects. But suppose we want state to be shared and mutated by multiple tasks. In this case, we can use [Ray's *actors*](https://ray.readthedocs.io/en/latest/actors.html) to encapsulate mutable state.\n",
    "\n",
    "*Optional:* Take a look at one interesting example of how to implement [distributed training with a parameter server using Ray actors](https://ray-project.github.io/2018/07/15/parameter-server-in-fifteen-lines.html). \n",
    "\n",
    "To create an actor, we decorate a Python class with the `@ray.remote` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd84d64d0ccc1729",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "    \n",
    "    def increment(self):\n",
    "        self.value += 1\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b0d6b2dd965571da",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We can create an actor instance by invoking `.remote()` on the actor class. This starts a new actor process, which holds a copy of the `Counter` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0481ce1a9e5aba1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "c = Counter.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-732ef8ed0b021f9a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We can run tasks on the actor process by invoking the actor's methods. These methods can mutate the actor's internal state (in this case, the field `self.value`). The actor executes tasks serially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67a29b4825d539d7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actor's value is 1.\n",
      "The actor's value is 2.\n"
     ]
    }
   ],
   "source": [
    "x1_id = c.increment.remote()\n",
    "print(\"The actor's value is {}.\".format(ray.get(c.get_value.remote())))\n",
    "\n",
    "x2_id = c.increment.remote()\n",
    "print(\"The actor's value is {}.\".format(ray.get(c.get_value.remote())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df8a1f4ff42d8e84",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Suppose we want multiple tasks, actors, or processes to invoke methods on a single actor. In this case, we can pass *actor handles* around between tasks. In the example below, we pass a handle to the counter actor to a handful of tasks executing in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-217811ba520bb99b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actor's value was 2 and now it is 42.\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def increment_counter(c):\n",
    "    for _ in range(10):\n",
    "        x_id = c.increment.remote()\n",
    "\n",
    "    # Wait for the last increment call to complete before returning.\n",
    "    ray.get(x_id)\n",
    "\n",
    "\n",
    "initial_value = ray.get(c.get_value.remote())\n",
    "\n",
    "# Start 4 tasks that run in parallel and all increment the counter.\n",
    "increment_results = [increment_counter.remote(c) for _ in range(4)]\n",
    "\n",
    "# Wait for all tasks to finish\n",
    "ray.get(increment_results)\n",
    "\n",
    "new_value = ray.get(c.get_value.remote())\n",
    "\n",
    "print(\"The actor's value was {} and now it is {}.\".format(initial_value, new_value))\n",
    "assert new_value - initial_value == 4 * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bb141de5cf51759",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5\n",
    "This question will take a different approach to solving the word-count problem from Question 4.\n",
    "\n",
    "Instead of launching four tasks that compute word counts and then aggregating the results on the \"driver\" process that issued the tasks, we are going to create a separate `ResultAggregator` actor for doing the aggregation. We will start four tasks that each compute frequencies for a given URL and then push those frequencies to the aggregator. The main \"driver\" process will then fetch the aggregated results from the aggregator.\n",
    "\n",
    "The code below implements a serial version of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAggregator:\n",
    "    \"\"\"Aggregates word frequencies\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_frequencies = {}\n",
    "    \n",
    "    def add_frequencies(self, frequencies):\n",
    "        \"\"\"Adds a new dictionary mapping words to word frequencies to the overall word frequencies\"\"\"\n",
    "        self.total_frequencies = merge_dicts(self.total_frequencies, frequencies)\n",
    "    \n",
    "    def get_frequencies(self):\n",
    "        \"\"\"Returns a dictionary mapping each word to its frequency\"\"\"\n",
    "        return self.total_frequencies\n",
    "\n",
    "\n",
    "def add_results(url, result_aggregator):\n",
    "    \"\"\"Downloads text from the url, counts the word frequencies, and adds the result to result_aggregator\"\"\"\n",
    "    # Download the text of the play\n",
    "    text = download_text(url)\n",
    "    # Count the frequency of each word in the play\n",
    "    frequencies = count_words(text)\n",
    "    # Add the results to the aggregator\n",
    "    done = result_aggregator.add_frequencies(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "awefawefaewf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting the words took 3.088740587234497 seconds.\n"
     ]
    }
   ],
   "source": [
    "result_aggregator = ResultAggregator()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "get_and_add_frequencies = [add_results(url, result_aggregator) for url in urls]\n",
    "\n",
    "# Get the results\n",
    "total_frequencies = result_aggregator.get_frequencies()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Counting the words took {} seconds.\".format(end_time - start_time))\n",
    "\n",
    "serial_words = most_used_words(total_frequencies, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e034af828b8433e9",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5a\n",
    "\n",
    "Now implement a parallel version in which `ResultAggregator` is an actor, and `add_results` is a remote function.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ResultAggregator(object):\n",
    "    \"\"\"Aggregates word frequencies\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_frequencies = {}\n",
    "    \n",
    "    def add_frequencies(self, frequencies):\n",
    "        \"\"\"Adds a new dictionary mapping words to word frequencies to the overall word frequencies\"\"\"\n",
    "        self.total_frequencies = merge_dicts(self.total_frequencies, frequencies)\n",
    "    \n",
    "    def get_frequencies(self):\n",
    "        \"\"\"Returns a dictionary mapping each word to its frequency\"\"\"\n",
    "        return self.total_frequencies\n",
    "\n",
    "@ray.remote\n",
    "def add_results(url, result_aggregator):\n",
    "    \"\"\"Downloads text from the url, counts the word frequencies, and adds the result to result_aggregator\"\"\"\n",
    "    text = download_text(url)\n",
    "    frequencies = count_words(text)\n",
    "    result_aggregator.add_frequencies.remote(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q5a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5b\n",
    "\n",
    "Now use your modified `ResultAggregator` and `add_results` created above to count word frequencies. See the code cell directly above Question 5a for reference.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting the words took 1.5965900421142578 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create an instance of a ResultAggregator actor\n",
    "result_aggregator = ResultAggregator.remote()\n",
    "\n",
    "# Call the add_results remote function on each URL\n",
    "get_and_add_frequencies = [add_results.remote(url, result_aggregator) for url in urls]\n",
    "\n",
    "# Wait for all add_results remote functions to complete\n",
    "ray.get(get_and_add_frequencies)\n",
    "\n",
    "# Get the results from the actor\n",
    "total_frequencies = ray.get(result_aggregator.get_frequencies.remote())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Counting the words took {} seconds.\".format(end_time - start_time))\n",
    "\n",
    "parallel_words = most_used_words(total_frequencies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q5b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6a\n",
    "\n",
    "How likely from 1 to 10 are you to use Ray in future projects? 1 is will not use Ray, 10 is will definitely use Ray.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeliness_to_use_ray = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q6a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "How could this homework be better? Is there anything you found especially difficult or confusing? What parts did you like?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "This was really interesting. I got stuck at a few parts but the answers were pretty intuitive for the most part.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 1\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q6b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15e2b642b7fe20d5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Other Links\n",
    "\n",
    "You've seen above how Ray makes it easy to implement a system like MapReduce as a library on top of Ray. A handful of libraries have been implemented on top of Ray. You may be interested in taking a look at the following:\n",
    "- [*Tune*: Distributed hyperparameter search](https://ray.readthedocs.io/en/latest/tune.html)\n",
    "([github](https://github.com/ray-project/ray/tree/master/python/ray/tune))\n",
    "- [*RLlib*: Scalable reinforcement learning](https://ray.readthedocs.io/en/latest/rllib.html)\n",
    "([github](https://github.com/ray-project/ray/tree/master/python/ray/rllib))\n",
    "- [*Modin*: Speeding up Pandas](http://modin.org/)\n",
    "([github](https://github.com/modin-project/modin))\n",
    "\n",
    "Ray, Tune, RLlib, and Modin are research projects in UC Berkeley's RISElab. If you're interested in contributing, take a look at the project's codebase on Github!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Content: K-means clustering and Hyperparameter Tuning\n",
    "\n",
    "Feel free to checkout notebook [k-means.ipynb](k-means.ipynb) for more optional content. We will show how to use ray to distribute k-means clustering algorithm. In addition, we will show how to make parallel hyperparamter search over it. \n",
    "\n",
    "In the end, you will produce something nice looking like this!\n",
    "\n",
    "<img src=\"https://i.imgur.com/TSxwgKI.png\" alt=\"k-means\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'hw7.ipynb'.\n",
      "Submit... 100% complete\n",
      "Submission successful for user: gottiparthy.ani@berkeley.edu\n",
      "URL: https://okpy.org/cal/data100/sp19/hw7/submissions/wVv0DR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
